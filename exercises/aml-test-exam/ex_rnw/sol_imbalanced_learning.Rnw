
The following data set contains $n = 13$ datapoints, the triangles denote class $+1$ and the circles denote class $-1.$

		\begin{figure}[ht!]
    \centering
    <<echo = FALSE, fig.height = 3, fig.width = 4, warnings= FALSE>>=
    library(ggplot2)
    library(ggforce)
    library(gridExtra)
    data = data.frame(
      x1 = c(1  , 1.5, 1.7, 2  , 2.2, 2.4, 2.6, 2.4,    2.6, 2.8, 3, 1.7, 3.3) -1,
      x2 = c(1.5, 1.9, 0.8, 1.2, 2.1, 1.7, 1.1, 2.6,   2.7, 2.3, 2.5, 2.6, 1.3) -0.8,
      y = as.factor(c(rep(-1,8),c(1,1),rep(-1,3))))
    
    p = ggplot(data = data) + geom_abline(slope=-1,intercept = 3) + geom_circle(aes(x0=1.5, y0=1.85, r=0.15), color='red', lwd=1.5, inherit.aes=FALSE)  + geom_circle(aes(x0=1.9, y0=1.6, r=0.15),  color='red', lwd=1.5, inherit.aes=FALSE) + geom_point(aes(x = x1, y = x2, shape = y, color = y), size = 4)  + theme_minimal() + xlim(0,2.5) + ylim(0, 2) + theme(legend.position = "none") + coord_fixed()
    
    p
    
    @
    \end{figure}


\begin{enumerate}
	%	
	\item Let $f(\xv) = 2 \cdot \mathds{1}_{[  \thetav^\top \xv \ge 3]} -1 $ with $\thetav=(1,1)^\top.$ Specify the confusion matrix of $f$ and compute its accuracy as well as its $F_1$ score.
	
		 \item[]	{\color{blue} \textbf{Solution:}   
		%	
		The decision boundary of the classifier is specified by
%		
		\begin{align*}
%			
			\thetav^\top \xv = 3 \quad &\Leftrightarrow \quad x_1+x_2 = 3 \quad \Leftrightarrow \quad x_2 = 3 - x_1.
		%		
		\end{align*}
		%
		
		

		
		
		
		This leads to the following confusion matrix
%		
		
			\begin{center}
				\begin{tabular}{cc|cc}
					& &\multicolumn{2}{c}{True class} \\
					& & $y=1$ & $y=-1$  \\
					\hline
					\multirow{2}{*}{\parbox{0.3cm}{Pred.  class}}& $\hat y$ = 1     & 2               & 2\\
					& $\hat y$ = -1 & $0$              &  9  \\
				\end{tabular}
			\end{center}
		
		Thus, the true positive rate is $\rho_{TPR} = \frac{TP}{TP + FN} = 1$ and the positive predictive value $\rho_{PPV} = \frac{TP}{TP + FP} = 1/2.$ Accordingly, $$\rho_{F_1} = 2 \frac{\rho_{PPV} \cdot \rho_{TPR}}{\rho_{PPV} + \rho_{TPR}} = 2/3$$ and $$\rho_{ACC} = \frac{TP + TN}{n} = \frac{11}{13.}$$
		
%		
	} 
	
	%
	\item Find all Tomek links with respect to the Euclidean distance on $\Xspace$ in the data set and remove the instances in each Tomek link belonging to the majority class. Repeat the computation in (a).  
	
	  \item[]	{\color{blue} \textbf{Solution:}   
		%	
		There are two Tomek links in the data (encircled in red).
		%
		If we remove the majority class instances respectively we obtain the confusion matrix
		\begin{center}
			\begin{tabular}{cc|cc}
				& &\multicolumn{2}{c}{True class} \\
				& & $y=1$ & $y=-1$  \\
				\hline
				\multirow{2}{*}{\parbox{0.3cm}{Pred.  class}}& $\hat y$ = 1     & 2               & 0\\
				& $\hat y$ = -1 & $0$              &  9  \\
			\end{tabular}
		\end{center}
		%
		Thus, the true positive rate is $\rho_{TPR} = \frac{TP}{TP + FN} = 1$ and the positive predictive value $\rho_{PPV} = \frac{TP}{TP + FP} = 1.$ Accordingly, $$\rho_{F_1} = 1$$ and $$\rho_{ACC} = 1.$$
		
		%		
	} 
	%	
	\item What is the accuracy of the classifier $f_-(\xv) = -1$ before  and after removing the Tomek links?
	
		
	 \item[]	{\color{blue} \textbf{Solution:}   
		%	
		Before removing the Tomek links: $$\rho_{ACC}(f_-) = \frac{11}{13}.$$
%		
		After removing the Tomek links: $$\rho_{ACC}(f_-) = \frac{9}{11}.$$		
		%		
	} 
	%
	%
\end{enumerate}